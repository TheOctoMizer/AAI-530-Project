{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lstm import TrafficLSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(data_path):\n",
    "    # Read the CSV file into a DataFrame\n",
    "    df = pd.read_csv(data_path)\n",
    "    \n",
    "    # Convert `Traffic Situation` to categorical data type\n",
    "    df['Traffic Situation'] = df['Traffic Situation'].astype('category')\n",
    "    \n",
    "    # Create numerical mapping for traffic situations\n",
    "    new_category_mapping = {category: i for i, category in enumerate(df['Traffic Situation'].cat.categories)}\n",
    "    df['Traffic Situation Num'] = df['Traffic Situation'].map(new_category_mapping)\n",
    "    \n",
    "    # One-hot encode categorical features\n",
    "    encoder = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\n",
    "    encoded_features = encoder.fit_transform(df[['Day of the week']])\n",
    "    encoded_df = pd.DataFrame(encoded_features, columns=encoder.get_feature_names_out(['Day of the week']))\n",
    "    \n",
    "    # Scale numerical features\n",
    "    scaler = MinMaxScaler()\n",
    "    numerical_features = ['CarCount', 'BikeCount', 'BusCount', 'TruckCount', 'Total']\n",
    "    df[numerical_features] = scaler.fit_transform(df[numerical_features])\n",
    "    \n",
    "    # Combine features\n",
    "    X = pd.concat([df[['Time', 'Date'] + numerical_features], encoded_df], axis=1)\n",
    "    \n",
    "    # Convert Time to seconds since midnight\n",
    "    X['Time'] = X['Time'].apply(convert_time_to_seconds)\n",
    "    \n",
    "    return X, df['Traffic Situation Num'], df['Total']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_time_to_seconds(time_str):\n",
    "    time_part, meridiem = time_str.split(' ')\n",
    "    hours, minutes, seconds = map(int, time_part.split(':'))\n",
    "    \n",
    "    if meridiem == 'PM' and hours != 12:\n",
    "        hours += 12\n",
    "    elif meridiem == 'AM' and hours == 12:\n",
    "        hours = 0\n",
    "        \n",
    "    return hours * 3600 + minutes * 60 + seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrafficDataset(Dataset):\n",
    "    def __init__(self, X, y_traffic_situation, y_total):\n",
    "        self.X = torch.tensor(X.values, dtype=torch.float32).unsqueeze(1)\n",
    "        self.y_traffic_situation = torch.tensor(y_traffic_situation.values, dtype=torch.long)\n",
    "        self.y_total = torch.tensor(y_total.values, dtype=torch.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y_traffic_situation[idx], self.y_total[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, test_loader, num_epochs, device):\n",
    "    # Use AdamW optimizer with weight decay\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=0.01)\n",
    "    \n",
    "    # Loss functions\n",
    "    criterion_classification = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
    "    criterion_regression = nn.MSELoss()\n",
    "    \n",
    "    # Learning rate scheduler\n",
    "    scheduler = torch.optim.lr_scheduler.OneCycleLR(\n",
    "        optimizer,\n",
    "        max_lr=learning_rate,\n",
    "        epochs=num_epochs,\n",
    "        steps_per_epoch=len(train_loader),\n",
    "        pct_start=0.3,\n",
    "        anneal_strategy='cos'\n",
    "    )\n",
    "    \n",
    "    # Training loop\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        pbar = tqdm(train_loader, desc=f'Epoch {epoch+1}/{num_epochs}')\n",
    "        total_loss = 0\n",
    "        \n",
    "        for i, (inputs, labels_classification, labels_regression) in enumerate(pbar):\n",
    "            inputs = inputs.to(device)\n",
    "            labels_classification = labels_classification.to(device)\n",
    "            labels_regression = labels_regression.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs_classification, outputs_regression = model(inputs)\n",
    "            \n",
    "            loss_classification = criterion_classification(outputs_classification, labels_classification)\n",
    "            loss_regression = criterion_regression(outputs_regression.squeeze(), labels_regression)\n",
    "            loss = loss_classification * 0.7 + loss_regression * 0.3\n",
    "            \n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            \n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            pbar.set_postfix({'loss': f'{total_loss/(i+1):.4f}'})\n",
    "    \n",
    "    # Evaluation\n",
    "    evaluate_model(model, test_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, test_loader, device):\n",
    "    model.eval()\n",
    "    criterion_regression = nn.MSELoss()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        correct_classification = 0\n",
    "        total_classification = 0\n",
    "        total_loss_regression = 0\n",
    "        \n",
    "        pbar = tqdm(test_loader, desc='Evaluating')\n",
    "        \n",
    "        for inputs, labels_classification, labels_regression in pbar:\n",
    "            inputs = inputs.to(device)\n",
    "            labels_classification = labels_classification.to(device)\n",
    "            labels_regression = labels_regression.to(device)\n",
    "\n",
    "            outputs_classification, outputs_regression = model(inputs)\n",
    "            _, predicted_classification = torch.max(outputs_classification.data, 1)\n",
    "            total_classification += labels_classification.size(0)\n",
    "            correct_classification += (predicted_classification == labels_classification).sum().item()\n",
    "            loss_regression = criterion_regression(outputs_regression.squeeze(), labels_regression)\n",
    "            total_loss_regression += loss_regression.item()\n",
    "            \n",
    "            current_accuracy = 100 * correct_classification / total_classification\n",
    "            current_loss = total_loss_regression / (pbar.n + 1)\n",
    "            pbar.set_postfix({\n",
    "                'Accuracy': f'{current_accuracy:.2f}%',\n",
    "                'Reg Loss': f'{current_loss:.4f}'\n",
    "            })\n",
    "\n",
    "        accuracy_classification = 100 * correct_classification / total_classification\n",
    "        avg_loss_regression = total_loss_regression / len(test_loader)\n",
    "\n",
    "        print(f\"\\nFinal Results:\")\n",
    "        print(f\"Accuracy (Classification): {accuracy_classification:.2f}%\")\n",
    "        print(f\"Average Loss (Regression): {avg_loss_regression:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n",
      "Preparing data...\n",
      "Starting training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/50: 100%|██████████| 149/149 [00:04<00:00, 30.06it/s, loss=0.8663]\n",
      "Epoch 2/50: 100%|██████████| 149/149 [00:04<00:00, 29.97it/s, loss=0.6470]\n",
      "Epoch 3/50: 100%|██████████| 149/149 [00:03<00:00, 46.31it/s, loss=0.5515]\n",
      "Epoch 4/50: 100%|██████████| 149/149 [00:02<00:00, 61.02it/s, loss=0.5009]\n",
      "Epoch 5/50: 100%|██████████| 149/149 [00:02<00:00, 61.72it/s, loss=0.4726]\n",
      "Epoch 6/50: 100%|██████████| 149/149 [00:02<00:00, 60.88it/s, loss=0.4590]\n",
      "Epoch 7/50: 100%|██████████| 149/149 [00:02<00:00, 61.41it/s, loss=0.4582]\n",
      "Epoch 8/50: 100%|██████████| 149/149 [00:02<00:00, 61.08it/s, loss=0.4327]\n",
      "Epoch 9/50: 100%|██████████| 149/149 [00:02<00:00, 60.78it/s, loss=0.4237]\n",
      "Epoch 10/50: 100%|██████████| 149/149 [00:02<00:00, 60.56it/s, loss=0.4364]\n",
      "Epoch 11/50: 100%|██████████| 149/149 [00:02<00:00, 60.42it/s, loss=0.4343]\n",
      "Epoch 12/50: 100%|██████████| 149/149 [00:02<00:00, 60.88it/s, loss=0.4233]\n",
      "Epoch 13/50: 100%|██████████| 149/149 [00:02<00:00, 61.16it/s, loss=0.4127]\n",
      "Epoch 14/50: 100%|██████████| 149/149 [00:02<00:00, 60.60it/s, loss=0.4166]\n",
      "Epoch 15/50: 100%|██████████| 149/149 [00:02<00:00, 60.74it/s, loss=0.4174]\n",
      "Epoch 16/50: 100%|██████████| 149/149 [00:02<00:00, 60.73it/s, loss=0.4140]\n",
      "Epoch 17/50: 100%|██████████| 149/149 [00:02<00:00, 59.69it/s, loss=0.4091]\n",
      "Epoch 18/50: 100%|██████████| 149/149 [00:02<00:00, 59.43it/s, loss=0.4151]\n",
      "Epoch 19/50: 100%|██████████| 149/149 [00:02<00:00, 60.33it/s, loss=0.4084]\n",
      "Epoch 20/50: 100%|██████████| 149/149 [00:02<00:00, 58.81it/s, loss=0.4017]\n",
      "Epoch 21/50: 100%|██████████| 149/149 [00:02<00:00, 58.98it/s, loss=0.4085]\n",
      "Epoch 22/50: 100%|██████████| 149/149 [00:02<00:00, 58.37it/s, loss=0.4201]\n",
      "Epoch 23/50: 100%|██████████| 149/149 [00:02<00:00, 58.60it/s, loss=0.4033]\n",
      "Epoch 24/50: 100%|██████████| 149/149 [00:02<00:00, 59.46it/s, loss=0.4024]\n",
      "Epoch 25/50: 100%|██████████| 149/149 [00:02<00:00, 58.78it/s, loss=0.4052]\n",
      "Epoch 26/50: 100%|██████████| 149/149 [00:02<00:00, 60.57it/s, loss=0.4016]\n",
      "Epoch 27/50: 100%|██████████| 149/149 [00:02<00:00, 60.54it/s, loss=0.3996]\n",
      "Epoch 28/50: 100%|██████████| 149/149 [00:02<00:00, 60.28it/s, loss=0.3904]\n",
      "Epoch 29/50: 100%|██████████| 149/149 [00:02<00:00, 60.20it/s, loss=0.3980]\n",
      "Epoch 30/50: 100%|██████████| 149/149 [00:02<00:00, 60.78it/s, loss=0.3967]\n",
      "Epoch 31/50: 100%|██████████| 149/149 [00:02<00:00, 59.54it/s, loss=0.3975]\n",
      "Epoch 32/50: 100%|██████████| 149/149 [00:02<00:00, 58.77it/s, loss=0.3984]\n",
      "Epoch 33/50: 100%|██████████| 149/149 [00:02<00:00, 59.69it/s, loss=0.3883]\n",
      "Epoch 34/50: 100%|██████████| 149/149 [00:02<00:00, 58.45it/s, loss=0.3893]\n",
      "Epoch 35/50: 100%|██████████| 149/149 [00:02<00:00, 54.86it/s, loss=0.3896]\n",
      "Epoch 36/50: 100%|██████████| 149/149 [00:02<00:00, 59.76it/s, loss=0.3831]\n",
      "Epoch 37/50: 100%|██████████| 149/149 [00:02<00:00, 59.76it/s, loss=0.3789]\n",
      "Epoch 38/50: 100%|██████████| 149/149 [00:02<00:00, 59.73it/s, loss=0.3824]\n",
      "Epoch 39/50: 100%|██████████| 149/149 [00:02<00:00, 59.93it/s, loss=0.3726]\n",
      "Epoch 40/50: 100%|██████████| 149/149 [00:02<00:00, 57.28it/s, loss=0.3757]\n",
      "Epoch 41/50: 100%|██████████| 149/149 [00:02<00:00, 57.72it/s, loss=0.3734]\n",
      "Epoch 42/50: 100%|██████████| 149/149 [00:02<00:00, 59.59it/s, loss=0.3706]\n",
      "Epoch 43/50: 100%|██████████| 149/149 [00:02<00:00, 57.38it/s, loss=0.3800]\n",
      "Epoch 44/50: 100%|██████████| 149/149 [00:02<00:00, 59.76it/s, loss=0.3797]\n",
      "Epoch 45/50: 100%|██████████| 149/149 [00:02<00:00, 58.67it/s, loss=0.3731]\n",
      "Epoch 46/50: 100%|██████████| 149/149 [00:02<00:00, 56.54it/s, loss=0.3671]\n",
      "Epoch 47/50: 100%|██████████| 149/149 [00:02<00:00, 57.59it/s, loss=0.3733]\n",
      "Epoch 48/50: 100%|██████████| 149/149 [00:02<00:00, 59.57it/s, loss=0.3726]\n",
      "Epoch 49/50: 100%|██████████| 149/149 [00:02<00:00, 59.34it/s, loss=0.3780]\n",
      "Epoch 50/50: 100%|██████████| 149/149 [00:02<00:00, 57.65it/s, loss=0.3729]\n",
      "Evaluating: 100%|██████████| 38/38 [00:00<00:00, 181.54it/s, Accuracy=93.87%, Reg Loss=0.0060]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final Results:\n",
      "Accuracy (Classification): 93.87%\n",
      "Average Loss (Regression): 0.0038\n",
      "Model saved to 'traffic_lstm_model.pth'\n"
     ]
    }
   ],
   "source": [
    "data_path = \"TrafficTwoMonth.csv\"\n",
    "input_size = 14  # Will be determined from data\n",
    "hidden_size = 256\n",
    "num_layers = 4\n",
    "num_classes = 4\n",
    "global learning_rate\n",
    "learning_rate = 0.001\n",
    "num_epochs = 50\n",
    "batch_size = 32\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Prepare data\n",
    "print(\"Preparing data...\")\n",
    "X, y_traffic_situation, y_total = prepare_data(data_path)\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_traffic_situation_train, y_traffic_situation_test, y_total_train, y_total_test = \\\n",
    "    train_test_split(X, y_traffic_situation, y_total, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create datasets and dataloaders\n",
    "train_dataset = TrafficDataset(X_train, y_traffic_situation_train, y_total_train)\n",
    "test_dataset = TrafficDataset(X_test, y_traffic_situation_test, y_total_test)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Initialize model\n",
    "model = TrafficLSTM(input_size, hidden_size, num_layers, num_classes)\n",
    "model = model.to(device)\n",
    "\n",
    "# Train model\n",
    "print(\"Starting training...\")\n",
    "train_model(model, train_loader, test_loader, num_epochs, device)\n",
    "\n",
    "# Save the model\n",
    "torch.save(model.state_dict(), 'traffic_lstm_model.pth')\n",
    "print(\"Model saved to 'traffic_lstm_model.pth'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML-Torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
